""" Implementation of 2D ocular dominance model from G.J. Goodhill &
D.J. Willshaw (1990), "Application of the elastic net algorithm to the
formation of ocular dominance stripes", Network: Computation in Neural
Systems 1(1), p41-59.

NOT YET TESTED.  

$Id$
"""
_version__='$Revision$'


from RandomArray import *
from Numeric import *
from fixedpoint import FixedPoint

import topo.patterns.random
import topo.patterns.basic

from topo.base.boundingregion import BoundingBox
from topo.base.parameterclasses import DynamicNumber
from topo.base.parameterclasses import Number
from topo.base.sheet import Sheet
from topo.sheets.generatorsheet import GeneratorSheet

topo.sim.name = "goodhill_network90"


class ElasticNet(Sheet):
    """
    Basic elastic net sheet (work in progress..)
    """
    alpha = Number(default=0.2,bounds=(0,None),
                   doc="Scaling constant, contribution from neighbouring units")

    beta  = Number(default=2.0,bounds=(0,None),
                   doc="Scaling constant, contribution from neighbouring points on the net")
                   
    initial_k = Number(default=0.2,bounds=(0,None),
                   doc="Initial k")

    rate_of_k = Number(default=0.1,bounds=(0,None),
                   doc="Rate of reduction of k by 10%")

    two_l = Number(default=0.2,bounds=(0,None),
                   doc="Separation between the two layers of cells")

    two_d = Number(default=0.05,bounds=(0,None),
                   doc="Separation between the cells within a layer")


    def __init__(self,**params):
        super(ElasticNet,self).__init__(**params)
        # The elastic net is composed of a 2-D layer and has 40x40
        # points. There are 3 values rows,cols,z.  rows,cols is used
        # for the topography, and z is used for ocularity. Ocularity
        # represented by z gets randomised. The paper does not say how
        # much, but by the looks of the figures, is clear that z (the
        # V1 cortical layer's ocularity) can pass above the retinal
        # layers.  V1 is located between the two layers; the distance
        # between them is the two_l.

        gap=(self.two_l)/2
        self.retinasize=2 # 20  # Ideally, would get this info from the retina objects
        self.cortexsize=4 # 40

        # Initialize position of retinal and cortical units in 3D space
        self.Rretina= [[[0,0, gap] for i in range(self.retinasize)] for r in range(self.retinasize)]
        self.Lretina= [[[0,0,-gap] for i in range(self.retinasize)] for r in range(self.retinasize)]
        self.v1layer= [[[0,0,randint(-5,5)] for i in range(self.cortexsize)] for r in range(self.cortexsize)]

        #   The retinal cells have also a fixed separation between them, two_d
        for rows in range(self.retinasize):
            for cols in range(self.retinasize):
                self.Rretina[rows][cols][0]= self.Rretina[rows][cols][0]+(self.two_d*rows)
                self.Lretina[rows][cols][0]= self.Lretina[rows][cols][0]+(self.two_d*rows)                    
                self.Rretina[rows][cols][1]= self.Rretina[rows][cols][1]+(self.two_d*cols)                    
                self.Lretina[rows][cols][1]= self.Lretina[rows][cols][1]+(self.two_d*cols) 
       
        # The cells in V1 are randomly distributed, but (as in the
        # paper) some bias is introduced by making sure that the left
        # end of the sheet is at the left (position 0).  The rest get
        # randomized as described in the paper
        for rows in range(self.cortexsize):
            self.v1layer[rows][0]=[rows,0,randint(-10,10)]


    def input_event(self,conn,data):
        """
        Accept input from some sheet.  Call .present_input() to
        compute the stimulation from that sheet.
        """
        self.verbose("Time " + str(self.simulation.time()) + ":" +
                     " Received input from " + str(conn.src.name) +
                     " on dest_port " + str(conn.dest_port) +
                     " via connection " + conn.name + ".")

    def process_current_time(self):
        """
        Called by the simulation after all the events are processed for the 
        current time but before time advances.  Allows the event processor
        to send any events that must be sent before time advances to drive
        the simulation. 
        """
        self.learn()


    def learn(self):
#        for rows in range(self.cortexsize):
#            for cols in range(self.cortexsize):
#                for x to range(self.retinasize):
#                    for y to range(self.retinasize):
#                        phi=exp(-(abs(self.Rretina[rows][cols][0]-self.v1layer[rows][cols][0])))
#
#                    
#                self.Rretina[rows][cols]=alpha*citiesforce
       
        print "End."

     def calculate_maps(self):
         # Compute OD, position pref, etc. maps and insert into the sheet_view_dict
         # Example:
         #activity_copy = array(self.activity)
         #new_view = SheetView((activity_copy,self.bounds),
         #                     self.name,self.precedence,self.simulation.time())
         #self.sheet_view_dict['Activity']=new_view


### Sheets,connections,parameters


topo.sim['LeftRetina']=GeneratorSheet(nominal_density=2,period=1.0, phase=0.05,
                                      nominal_bounds=BoundingBox(radius=0.5))

topo.sim['RightRetina']=GeneratorSheet(nominal_density=2, period=1.0, phase=0.05,
                                       nominal_bounds=BoundingBox(radius=0.5))

topo.sim['V1'] = ElasticNet(nominal_density=40,nominal_bounds=BoundingBox(radius=0.5))

## Dummy right retina; used only for calling the elasticnet function and for visualization
## JABALERT: should also use it to control the parameters of the retina
topo.sim.connect('RightRetina','V1',name='RV1',delay=0.05,src_port="Activity")

## Dummy left retina; used only for visualization
topo.sim.connect('LeftRetina','V1',name='LV1',delay=0.05,src_port="Activity")
