""" 
Simulation for development of stable orientation maps based on
lissom_oo_or_noshrinking.ty (see Chapman et. al, J. Neurosci
16(20):6443, 1996).  The development is also robust to changes in the
input (e.g., number of Gaussians in the retinal input or brightness of
each Gaussian).

Afferent projection activities for individual units are scaled based
on maintaining a target average afferent activity. The learning rates
of afferent projections are also scaled in order to maintain the
overall rate of learning despite changes in LGN activity.

The sigmoidal output function for V1 is regulated using the Triesch
rule (Jochen Triesch, ICANN 2005, LNCS 3696 pp.65-70), which maintains
stable activity in V1 given a target average activity. 

The afferent target and the target V1 activity are adapted based on
the frequency of occurence of activation in V1 by setting the
frequency parameter. A simulation using 2 Gaussian patterns per
iteration as the retinal input has a frequency parameter of 2
therefore frequency values should be chosen relative to this, i.e. a
simulation using 4 Gaussian patterns per iteration has an optimum
frequency parameter of ~ 3.56, natural images have a frequency ~ 5.0
and noisy disks a frequency ~ 7.5. 

The balance parameter that changes the balance between afferent input
and V1 activity can also be adjusted to improve map organization.

This script is set up as a tracking version for plotting sheet and
projection attributes throughout development and for reproducing the
published results which include examples where scaling is turned off.

To turn tracking off set tracking=False

Not yet fully tested.
$Id$
"""
__version__='$Revision: 8197 $'

import fixedpoint
import numpy

from math import pi, sqrt
from fixedpoint import FixedPoint

import topo.pattern.basic
import topo.pattern.random

from topo.pattern.basic import Gaussian
from topo.sheet.lissom import JointScaling, LISSOM
from topo.sheet.generator import GeneratorSheet
from topo.projection.basic import CFProjection, SharedWeightCFProjection
from topo.responsefn.optimized import CFPRF_DotProduct_opt
from topo.base.cf import CFSheet, CFPLF_PluginScaled, CFPOF_Plugin
from topo.base.boundingregion import BoundingBox
from topo.learningfn.optimized import CFPLF_Hebbian_opt
from topo.outputfn.optimized import CFPOF_DivisiveNormalizeL1_opt
from topo.outputfn.basic import PiecewiseLinear, DivisiveNormalizeL1, PipelineOF, IdentityOF, ActivityAveragingOF, AttributeTrackingOF 
from topo.outputfn.basic import Sigmoid, HalfRectify, HomeostaticMaxEnt
from topo.misc.numbergenerators import UniformRandom, BoundedNumber, ExponentialDecay
from topo.pattern.image import Image

import contrib.jsldefs
from contrib.jsldefs import JointScaling_lronly, JointScaling_affonly, homeostatic_analysis_function

###############################################################
####Different input types which can be used for development###
dataset=locals().get('dataset',"Gaussian") #set the input type by choosing the dataset parameter 

if dataset=="Gaussian":
    input_type=Gaussian
    num_inputs=locals().get('num_inputs',2) #in the case where dataset=Gaussian, must also set the number of Gaussians per iteration, default is 2
    inputs=[input_type(x=UniformRandom(lbound=-0.75,ubound=0.75,seed=12+i),
                       y=UniformRandom(lbound=-0.75,ubound=0.75,seed=35+i),
                       orientation=UniformRandom(lbound=-pi,ubound=pi,seed=21+i),
                       size=0.088388, aspect_ratio=4.66667, scale= locals().get('scale', 1.0), bounds=BoundingBox(radius=1.125))
            #Set the contrast of the gaussian patterns by setting the scale parameter.
            for i in xrange(num_inputs)]
    
    combined_inputs = topo.pattern.basic.SeparatedComposite(min_separation=0,generators=inputs)
    
elif dataset=="Natural":
    
    input_type=topo.pattern.image.Image
    image_filenames=["images/shouval/combined%02d.png"%(i+1) for i in xrange(25)]
    inputs=[input_type(filename=f,
                       size=10.0,  #size_normalization='original',(size=10.0)
                       x=UniformRandom(lbound=-0.75,ubound=0.75,seed=12),
                       y=UniformRandom(lbound=-0.75,ubound=0.75,seed=36),
                       orientation=UniformRandom(lbound=-pi,ubound=pi,seed=65))
		for f in image_filenames]

    combined_inputs =topo.pattern.basic.Selector(generators=inputs)

elif dataset=="NoisyDisks":
    disk_scale=locals().get('diskscale',0.35)
    #Set the contrast of the disk pattern by setting the disk_scale parameter, map development also depends on the contrast of the disk edges.
    input_type=topo.pattern.basic.Composite
    inputs=[input_type(operator=numpy.add,
                       generators=[topo.pattern.basic.Disk(x=UniformRandom(lbound=-2.125,ubound=2.125,seed=12),
                                                            y=UniformRandom(lbound=-2.125,ubound=2.125,seed=36),
                                                            size=2.0, aspect_ratio=1.0, scale=disk_scale,
                                                            offset=0.5,
                                                            bounds=BoundingBox(radius=1.125), smoothing=0.1),
                                   topo.pattern.random.UniformRandom(offset=locals().get('rand_offset',-0.5), scale=locals().get('rand_scale',1.0))])]
    #Set the scale of the noise by setting the rand_offset and rand_scale parameters, note that the disk/noise signal ratio also depends on the retinal density      
    combined_inputs =topo.pattern.basic.Selector(generators=inputs)

elif dataset=="Disks":
    disk_scale=locals().get('diskscale',0.5)
    input_type=topo.pattern.basic.Disk
    inputs=[input_type(x=UniformRandom(lbound=-2.125,ubound=2.125,seed=12),
                       y=UniformRandom(lbound=-2.125,ubound=2.125,seed=36),
                       size=2.0, aspect_ratio=1.0, scale=disk_scale,
                       offset=0.5,
                       bounds=BoundingBox(radius=1.125), smoothing=0.1)]
            
    combined_inputs =topo.pattern.basic.Selector(generators=inputs)

elif dataset=="NoisyDiskstoNatural":
    #This dataset mimics pre and post eye-opening development - scheduled changes must also be set to ensure the input pattern changes at simulated eye opening
    disk_scale=locals().get('diskscale',0.35)
    disks_input_type=topo.pattern.basic.Composite
    disks_inputs=[disks_input_type(operator=numpy.add,
                       generators=[topo.pattern.basic.Disk(x=UniformRandom(lbound=-2.125,ubound=2.125,seed=12),
                                                            y=UniformRandom(lbound=-2.125,ubound=2.125,seed=36),
                                                            size=2.0, aspect_ratio=1.0, scale=disk_scale,
                                                            offset=0.5,
                                                            bounds=BoundingBox(radius=1.125), smoothing=0.1),
                                   topo.pattern.random.UniformRandom(offset=locals().get('rand_offset',-0.5), scale=locals().get('rand_scale',1.0))])]

    combined_inputs =topo.pattern.basic.Selector(generators=disks_inputs)      
   
    
    natural_input_type=topo.pattern.image.Image
    image_filenames=["images/shouval/combined%02d.png"%(i+1) for i in xrange(25)]
    natural_inputs=[natural_input_type(filename=f,
                       size=10.0,  #size_normalization='original',(size=10.0)
                       x=UniformRandom(lbound=-0.75,ubound=0.75,seed=12),
                       y=UniformRandom(lbound=-0.75,ubound=0.75,seed=36),
                       orientation=UniformRandom(lbound=-pi,ubound=pi,seed=65))
		for f in image_filenames]

    natural_combined_inputs =topo.pattern.basic.Selector(generators=natural_inputs)

###############################################################################

#Sheet coordinates of units to track for debugging
units=locals().get('units',[(0.0, 0.0), (0.25,0.25), (0.49,0.49)])

#Quickly set sheet density, high_density = True in published figures.

high_density=locals().get('hd',False)
if high_density==True:
    default_density = 100
    default_retinal_density = 50 
else:
    default_density = locals().get('default_density',48)
    default_retinal_density = locals().get('default_retinal_density',default_density/2)
  
#Smoothing value for exponential averaging
smoothing=locals().get('smoothing',0.999)
V1_smoothing=locals().get('V1_smoothing',0.999) # Allows different smoothing for averaging  V1 activity and averaging afferent activity.

#Output functions: Sheets
#LGN
LGN_on_output_fn=HalfRectify()
LGN_off_output_fn=HalfRectify()

#Set targets based on frequency of occurance of V1 activation
frequency=locals().get('frequency',2)

#Target average afferent activity and target average V1 activity set based on
#frequency and balance between afferent and lateral activity
mu=locals().get('mu',0.0045*frequency)
balance = locals().get('balance',4.0)
afferent_target = locals().get('afferent_target',mu*balance)

#V1
tracking=locals().get('tracking', True) # Turn tracking on or off
triesch=locals().get('triesch', True) # Turn homeostatic adjustment of V1 output function on or off
scaling=locals().get('scaling',True) # Turn afferent scaling on or off
lr_scaling=locals().get('lr_scaling',True) # Turn scaling of afferent learning rate on or off


if tracking==True:
    if triesch==True:
        if scaling==True:
            if lr_scaling==True:
                Attrib_Tracker=AttributeTrackingOF(object="topo.sim['V1']", attrib_names=['x_avg', 'sf', 'lr_sf', 'scaled_x_avg'], units=units)
                HE=HomeostaticMaxEnt(smoothing=V1_smoothing,
                                              eta=locals().get('eta',0.016), mu=mu, step=9)
                V1_Tracker=AttributeTrackingOF(object=HE, coordframe="topo.sim['V1']",attrib_names=['a', 'b','y_avg'], units=units, step=9)
                V1_OF=PipelineOF(output_fns=[Attrib_Tracker, HE, V1_Tracker])
            else:
                Attrib_Tracker=AttributeTrackingOF(object="topo.sim['V1']", attrib_names=['x_avg', 'sf', 'scaled_x_avg'], units=units)
                HE=HomeostaticMaxEnt(smoothing=V1_smoothing,
                                              eta=locals().get('eta',0.016), mu=mu, step=9)
                V1_Tracker=AttributeTrackingOF(object=HE, coordframe="topo.sim['V1']",attrib_names=['a', 'b','y_avg'], units=units, step=9)
                V1_OF=PipelineOF(output_fns=[Attrib_Tracker, HE, V1_Tracker]) 
        else:
            if lr_scaling==True:
                Attrib_Tracker=AttributeTrackingOF(object="topo.sim['V1']", attrib_names=['lr_sf'], units=units)
                HE=HomeostaticMaxEnt(smoothing=V1_smoothing,  
                                              eta=locals().get('eta',0.016), mu=mu, step=9)
                V1_Tracker=AttributeTrackingOF(object=HE, coordframe="topo.sim['V1']",attrib_names=['a', 'b','y_avg'], units=units, step=9)
                V1_OF=PipelineOF(output_fns=[Attrib_Tracker, HE, V1_Tracker])
            else:
                HE=HomeostaticMaxEnt(smoothing=V1_smoothing, eta=locals().get('eta',0.016), mu=mu, step=9)
                V1_Tracker=AttributeTrackingOF(object=HE,coordframe="topo.sim['V1']", attrib_names=['a', 'b','y_avg'], units=units, step=9)
                V1_OF=PipelineOF(output_fns=[HE, V1_Tracker])
    else:
        if scaling==True:
            Attrib_Tracker=AttributeTrackingOF(object="topo.sim['V1']", attrib_names=['x_avg', 'sf','lr_sf', 'scaled_x_avg'], units=units)
            HE=Sigmoid(r=locals().get('a_init',12),k=locals().get('b_init',-5.5))
            AV=ActivityAveragingOF(smoothing=smoothing,step=1)
            V1_Tracker=AttributeTrackingOF(object=AV,coordframe="topo.sim['V1']", attrib_names=['x_avg'], units=units, step=1)
            V1_OF=PipelineOF(output_fns=[Attrib_Tracker, HE, AV, V1_Tracker])
        else:
            HE=Sigmoid(r=locals().get('a_init',12),k=locals().get('b_init',-5.5))
            AV=ActivityAveragingOF(smoothing=smoothing,step=1)
            V1_Tracker=AttributeTrackingOF(object=AV,coordframe="topo.sim['V1']", attrib_names=['x_avg'], units=units, step=1)
            V1_OF=PipelineOF(output_fns=[HE, AV, V1_Tracker])
else:
    if triesch==True:
        V1_OF=HE=HomeostaticMaxEnt(smoothing=V1_smoothing,eta=locals().get('eta',0.016), mu=mu, step=9)
    else:
        V1_OF=Sigmoid(r=locals().get('a_init',12),k=locals().get('b_init',-5.5))

       
#Output Functions: Projections
#Debugging
#LGNOnAfferent
if tracking==True:
    LGNOn_Avg=ActivityAveragingOF(smoothing=smoothing,step=1)
    LGNOn_Tracker=AttributeTrackingOF(object=LGNOn_Avg,coordframe="topo.sim['V1']", attrib_names=['x_avg'], units=units, step=1)
    LGNOn_OF = PipelineOF(output_fns=[LGNOn_Avg, LGNOn_Tracker])

    #LGNOffAfferent
    LGNOff_Avg=ActivityAveragingOF(smoothing=smoothing,step=1)
    LGNOff_Tracker=AttributeTrackingOF(object=LGNOff_Avg,coordframe="topo.sim['V1']", attrib_names=['x_avg'], units=units, step=1)
    LGNOff_OF = PipelineOF(output_fns=[LGNOff_Avg, LGNOff_Tracker])

    #LateralExcitatory
    LatEx_Avg=ActivityAveragingOF(initial_average=0.0,smoothing=smoothing,step=1)
    LatEx_Tracker=AttributeTrackingOF(object=LatEx_Avg,coordframe="topo.sim['V1']", attrib_names=['x_avg'], units=units, step=1)
    LatEx_OF = PipelineOF(output_fns=[LatEx_Avg, LatEx_Tracker])
    
    #LateralInhibitory
    LatIn_Avg=ActivityAveragingOF(initial_average=0.0,smoothing=smoothing,step=1)
    LatIn_Tracker = AttributeTrackingOF(object=LatIn_Avg,coordframe="topo.sim['V1']", attrib_names=['x_avg'], units=units, step=1)
    LatIn_OF = PipelineOF(output_fns=[LatIn_Avg, LatIn_Tracker])

# Specify weight initialization, response function, and learning function
CFProjection.cf_shape = topo.pattern.basic.Disk(smoothing=0.0)
CFProjection.weights_generator = topo.pattern.basic.Constant()
CFProjection.response_fn=CFPRF_DotProduct_opt()
CFProjection.learning_fn=CFPLF_Hebbian_opt()
CFProjection.weights_output_fn=CFPOF_DivisiveNormalizeL1_opt()
SharedWeightCFProjection.response_fn=CFPRF_DotProduct_opt()


# DoG weights for the LGN

centerg   = Gaussian(size=0.07385,aspect_ratio=1.0,output_fn=DivisiveNormalizeL1())
surroundg = Gaussian(size=0.29540,aspect_ratio=1.0,output_fn=DivisiveNormalizeL1())
    
on_weights = topo.pattern.basic.Composite(
    generators=[centerg,surroundg],operator=numpy.subtract)

off_weights = topo.pattern.basic.Composite(
    generators=[surroundg,centerg],operator=numpy.subtract)

#Function for generating Gaussian random initial weights
def gauss_rand(size):
    return topo.pattern.basic.Composite(operator=numpy.multiply, 
                                         generators=[Gaussian(aspect_ratio=1.0, size=size),
                                                     topo.pattern.random.UniformRandom()])

#Whether or not to use divisive weights normalization
norm=locals().get('norm',True)

if norm==False:
    pi=topo.base.cf.CFPOF_Plugin(single_cf_fn=topo.outputfn.basic.IdentityOF())
else:
    pi = None


###########################################
# build simulation

topo.sim['Retina']=GeneratorSheet(nominal_density=default_retinal_density,
                                  input_generator=combined_inputs,
                                  period=1.0, phase=0.05,
                                  nominal_bounds=BoundingBox(radius=0.5+0.25+0.375))

topo.sim['LGNOn']=CFSheet(nominal_density=default_retinal_density,
                          nominal_bounds=BoundingBox(radius=0.5+0.25),
                          output_fn=LGN_on_output_fn,
                          measure_maps=False)

topo.sim['LGNOff']=CFSheet(nominal_density=default_retinal_density,
                           nominal_bounds=BoundingBox(radius=0.5+0.25),
                           output_fn=LGN_off_output_fn,
                           measure_maps=False)


if scaling==False:
    if lr_scaling==True:
        #option for only scaling learning rate but not afferent projection
        topo.sim['V1'] = JointScaling_lronly(nominal_density=default_density,
                                             nominal_bounds=BoundingBox(radius=0.5),tsettle=9,
                                             plastic=True,output_fn=V1_OF,
                                             post_initialization_weights_output_fn=pi,
                                             smoothing=smoothing,target_lr=locals().get('target_lr',0.045))
    else:
        #option for no scaling 
        topo.sim['V1'] = LISSOM(nominal_density=default_density,tsettle=9,
                                nominal_bounds=BoundingBox(radius=0.5),
                                output_fn=V1_OF)
        

else:
    if lr_scaling==True:
        #option for scaling both afferent projection and afferent learning rate 
        topo.sim['V1'] = JointScaling(nominal_density=default_density,
                                      nominal_bounds=BoundingBox(radius=0.5),tsettle=9,
                                      plastic=True,output_fn=V1_OF,
                                      post_initialization_weights_output_fn=pi,
                                      target=afferent_target, smoothing=smoothing,
                                      target_lr=locals().get('target_lr',0.045))
    else:
        #option for scaling only afferent projection but not afferent learning rate 
        topo.sim['V1'] = JointScaling_affonly(nominal_density=default_density,
                                              nominal_bounds=BoundingBox(radius=0.5),tsettle=9,
                                              plastic=True,output_fn=V1_OF,
                                              post_initialization_weights_output_fn=pi,
                                              target=afferent_target, smoothing=smoothing)


topo.sim.connect('Retina','LGNOn',delay=FixedPoint("0.05"),
                 connection_type=SharedWeightCFProjection,strength=locals().get('ret_strength',2.33),
                 nominal_bounds_template=BoundingBox(radius=0.375),name='Afferent',
                 weights_generator=on_weights)

topo.sim.connect('Retina','LGNOff',delay = FixedPoint("0.05"),
                 connection_type=SharedWeightCFProjection,strength=locals().get('ret_strength',2.33),
                 nominal_bounds_template=BoundingBox(radius=0.375),name='Afferent',
                 weights_generator=off_weights)

topo.sim.connect('LGNOn','V1',delay=FixedPoint("0.05"), dest_port=('Activity','JointNormalize', 'Afferent'),
                 connection_type=CFProjection,
                 learning_fn=CFPLF_PluginScaled(),
                 strength=1.0,name='LGNOnAfferent',
                 weights_generator=gauss_rand(size=2*0.27083),
                 nominal_bounds_template=BoundingBox(radius=0.27083),
		 learning_rate=locals().get('aff_lr',0.137))
               		 
topo.sim.connect('LGNOff','V1',delay=FixedPoint("0.05"), dest_port=('Activity','JointNormalize', 'Afferent'),
		 connection_type=CFProjection,
                 learning_fn=CFPLF_PluginScaled(),
                 strength=1.0,name='LGNOffAfferent',
                 weights_generator=gauss_rand(size=2*0.27083),
                 nominal_bounds_template=BoundingBox(radius=0.27083),
		 learning_rate=locals().get('aff_lr',0.137))

topo.sim.connect('V1','V1',delay=FixedPoint("0.05"),name='LateralExcitatory',
                 connection_type=CFProjection,
                 strength=1.0*locals().get('exc_strength',1.0),
                 weights_generator=topo.pattern.basic.Gaussian(aspect_ratio=1.0, size=0.04),
                 nominal_bounds_template=BoundingBox(radius=0.03),learning_rate=0.0) 
        
topo.sim.connect('V1','V1',delay=FixedPoint("0.05"),name='LateralInhibitory',
                 connection_type=CFProjection,
                 strength=-1.0*locals().get('inh_strength',1.0),
                 #inh_strength should be increased for more distributed datasets i.e. when the frequency parameter is higher
                 weights_generator=gauss_rand(size=2*0.22917),
                 nominal_bounds_template=BoundingBox(radius=0.22917),learning_rate=locals().get('lat_lr',1.80873))


#Output functions for tracking
if tracking==True:
    topo.sim["V1"].projections()["LGNOnAfferent"].output_fn=LGNOn_OF
    topo.sim["V1"].projections()["LGNOffAfferent"].output_fn=LGNOff_OF
    topo.sim["V1"].projections()["LateralExcitatory"].output_fn=LatEx_OF
    topo.sim["V1"].projections()["LateralInhibitory"].output_fn=LatIn_OF


# default locations for model editor
topo.sim.grid_layout([[None,    'V1',     None],
                      ['LGNOn', None,     'LGNOff'],
                      [None,    'Retina', None]], xstart=150)

### Input pattern changes
changetime = locals().get('changetime',6000)# Time at which patterns or strengths are set to change

changetargets = locals().get('changetargets',True) #If false, targets for afferent scaling and output function adjustment are not changed.
if dataset=="NoisyDiskstoNatural":
    if changetargets==True:
        new_frequency = locals().get('new_frequency',5)
        new_balance = locals().get('new_balance',4)
        new_mu=0.0045*new_frequency
        new_afferent_target = new_mu*new_balance
        topo.sim.schedule_command(changetime,'topo.sim["Retina"].set_input_generator(natural_combined_inputs,push_existing=False)')
        topo.sim.schedule_command(changetime,'topo.sim["V1"].target=new_afferent_target')
        if tracking==True:
            topo.sim.schedule_command(changetime,'topo.sim["V1"].output_fn.output_fns[1].mu=new_mu')
        else:
            topo.sim.schedule_command(changetime,'topo.sim["V1"].output_fn.mu=new_mu')
    else:
        topo.sim.schedule_command(changetime,'topo.sim["Retina"].set_input_generator(natural_combined_inputs,push_existing=False)')


#can set strength of retina to lgn projections to change during development  
changestrength = locals().get('changestrength',False)
if changestrength==True:
    new_strength = locals().get('new_strength',2.0)
    topo.sim.schedule_command(changetime,'topo.sim["LGNOn"].projections()["Afferent"].strength=new_strength')
    topo.sim.schedule_command(changetime,'topo.sim["LGNOff"].projections()["Afferent"].strength=new_strength')


import topo.command.analysis
topo.command.analysis.plotgroups["Orientation Preference"].update_command="measure_or_pref(pattern_presenter=PatternPresenter(pattern_generator=SineGrating(),apply_output_fn=True,duration=1.0))"

import topo.analysis.featureresponses
topo.analysis.featureresponses.FeatureMaps.selectivity_multiplier=1.0
