
import os, itertools, string, logging, json, re, glob,fnmatch,  base64
import numpy as np
import param
from dispatch import TaskSpecifier, StaticSpecs

try: from PIL import Image
except: Image = None

class FileLoader(object):
    def __init__(self, extensions, transform):
        self.extensions = extensions
        self.transform = transform

class PILImageLoader(FileLoader):
    def __init__(self, extensions, transform=lambda x:x, mode='RGB'):
        if Image is None:
            raise Exception("Cannot use PILImageLoader without PIL")
        super(PILImageLoader, self).__init__(extensions, transform)
        self.mode = mode

    def filedata(self, path):
        im = Image.open(path)
        return self.transform(im.convert(self.mode))

    def metadata(self, path, fdata):
        meta_keys = ['width', 'height', 'info', 'format','mode']
        meta_info =  fdata.size+(fdata.info, fdata.format, fdata.mode)
        return dict(zip(meta_keys, meta_info))

class Base64ImageLoader(PILImageLoader):
    def __init__(self, extensions, transform=lambda x:x):
        super(Base64ImageLoader, self).__init__(extensions, transform)

    def filedata(self, path):
        (_, extension) = os.path.splitext(path)
        prefix = 'data:image/%s;base64,' % extension[1:]
        with open(path,"rb") as f:
            b64 = base64.encodestring(f.read())
            return prefix + b64

    def metadata(self, path, fdata):
        try:
            fdata = Image.open(path)
            return super(Base64Image, self).metadata(path, fdata)
        except:
            logging.info("Cannot use PIL to extract metadata")
            return {}

class NumpyLoader(FileLoader):
    def __init__(self, extensions, transform=lambda x:x):
        super(NumpyLoader, self).__init__(extensions, transform)

    def filedata(self, path):
        with open(path, 'rb') as f: return np.load(f)

    def metadata(self, path, fdata):
        return {'dtype':str(fdata.dtype), 'shape':fdata.shape}


class Collate(param.Parameterized):
    """ Collate objects allow you to associate data generated by running dispatch to
    the specifications that were executed. You can use the constructor or the
    insert_columns method to associate a list of values to the corresponding
    specifications. This class is particularly useful for extracting the filenames of
    interest and associating them to a given key.

    Note that all the inserted data is converted to string representation to allow
    conversion to a StaticSpecs specifier. Supplying a Collate object to a Select
    object allows you to handle numeric values easily without affecting the
    underlying string representation."""

    root_directory = param.String(default=None, allow_None=True, doc='''
             The absolute path to the root directory. Required in order to be able to
             extract file data from the dispatches.''')

    @classmethod
    def from_log(cls, log_path, tid_key='tid'):
        """ Parses the log file generated by a launcher and returns
        the appropriate arguments to construct a Collate object. The
        'tid' field is optionally added.  If tid_key is None, the
        parsed tids are not added to the spec. Use as follows:
        Collate(*Collate.from_log())
        """
        log_path = os.path.abspath(param.normalize_path(log_path))
        (root_directory,_) = os.path.split(log_path)

        with open(log_path,'r') as log:
            splits = (str(line).split() for line in log)

            split_tuples =  [(split[0], json.loads(" ".join(split[1:]))  ) for split in splits]
            split_tuples =[(str(tid), spec) for (tid, spec) in split_tuples]

        _, specs =  zip(*split_tuples)
        if tid_key is not None:
            keys = sorted(set([str(k) for spec in specs for k in spec.keys()]))
            assert tid_key not in keys, "The chosen tid key '%s' already exists." % tid_key
            specs = [dict(spec, **{tid_key:tid}) for (tid,spec) in split_tuples]

        return [root_directory, specs]

    def __init__(self, root_directory, spec_list, **columns):

        spec_list = [dict([(str(k),str(v)) for (k,v) in spec.items()]) for spec in spec_list]
        assert all([len(columns[k]) == len(spec_list) for k in columns]), \
            'All result lists must be the same length as the spec_list.'

        fields = sorted(set([k for spec in spec_list for k in spec.keys()]))
        assert set(columns.keys()) & set(fields) == set(), ' Result keys overlap existing keys'

        self._datakeys = []
        self._filekeys = []
        self._partitionedkeys = []

        self.spec_list = spec_list
        self.insert_columns(**columns)
        self.root_directory = root_directory

    def __len__(self):           return len(self.spec_list)

    def __getitem__(self, name): return self.spec_list[name]

    def fields(self):
        return sorted(set([k for spec in self.spec_list for k in spec.keys()]))

    def insert_columns(self, **columns):
        collated_list =[]
        for (i,spec) in enumerate(self.spec_list):
            extended_spec =  dict([(k, str(columns[k][i])) for k  in columns]+spec.items())
            collated_list.append(extended_spec)
        self.spec_list = collated_list
        self._datakeys += columns.keys()

    def filelist(self, fstring, basename=True):
        flist = fstring.rsplit(' ')
        if basename: flist = [os.path.basename(f) for f in flist ]
        return flist

    def _matcher(self, pattern, root_directory):
        path_pattern = os.path.join(root_directory, pattern)
        path_pattern = os.path.abspath(path_pattern)
        format_keys = [k for (_,k,_,_) in string.Formatter().parse(path_pattern) if k is not None]
        if format_keys == []: return lambda spec: glob.glob(path_pattern)
        else:               return lambda spec: glob.glob(path_pattern.format(**spec))

    def extract_filelist(self, key, patterns, key_type={}):
        ''' Patterns is list of patterns. Patterns are paths that support globbing
        and dictionary format keys eg. {tid}. '''
        assert key not in self.fields(), "Cannot use key already in fields"

        matchers = [self._matcher(pattern, self.root_directory) for pattern in patterns]
        extended_speclist = []
        for spec in self.spec_list:
            typed_spec = [(k, key_type[k](v) if k in key_type else v) for (k,v) in spec.items()]
            matchgroups = [matcher(dict(typed_spec)) for matcher in matchers]
            matches = ' '.join([match for group in matchgroups for match in group])
            extended_speclist.append(dict(spec, **{key:matches}))
        self.spec_list = extended_speclist
        self._filekeys.append(key)

    def partition_by_filename(self, src_key, dest_key, pattern, **values):
        """ """
        format_keys = [k for (_,k,_,_) in string.Formatter().parse(pattern) if k is not None]
        supplied_key_set = set(values.keys())
        assert src_key in self.fields(), "The source_key must be available in specification keys"
        assert supplied_key_set & set(self.fields()) == set(), \
            "Cannot use key already used in specification keys"
        assert set(format_keys) == supplied_key_set, \
            'Keys provided must exactly match set of keys used in pattern'

        partitioned_specs = []
        for spec in self.spec_list:
            for vals in itertools.product(*[values[k] for k in format_keys]):
                extension = dict(zip(format_keys, vals))
                matches = [path for path in spec[src_key].rsplit(' ')
                           if fnmatch.fnmatch(os.path.basename(path), pattern.format(**extension))]
                items = (spec.items()
                         + [ (k,str(v)) for (k,v) in extension.items() ]
                         + [(dest_key,' '.join(matches))])
                partitioned_specs.append(dict([(k,v) for (k,v) in items if k != src_key]))

        self._filekeys.remove(src_key)
        self._filekeys.append(dest_key)
        self._partitionedkeys += format_keys
        self.spec_list = partitioned_specs

    def extract_files(self, fileloader, source_key, label_key=None):

        extracted = []; label_vals = []; ind=0
        for spec in list(self):
            all_fpaths = self.filelist(spec[source_key], basename=False)
            fpaths = [fpath for fpath in all_fpaths
                      if os.path.splitext(fpath)[1] in fileloader.extensions]
            label_inds = range(ind, ind+len(fpaths)); ind += len(fpaths)
            labels = ['%s_%d' % (source_key, i) for i in label_inds]
            label_vals.append(' '.join(labels))

            fdata = [fileloader.filedata(path) for path in fpaths]
            metadata = [ fileloader.metadata(fpath, fdatum)
                         for (fpath, fdatum) in zip(fpaths, fdata)]
            extracted.append((fdata, metadata, labels))

        if label_key is not None: self.insert_columns(**{label_key:label_vals})
        return zip(*extracted)

    def show(self, summary=False, basename=True, spec_keys=[]):

        pkeys =  "Partitioned keys: %s" % ', '.join(["'%s'" % el for el in self._partitionedkeys])
        dkeys =  "Data keys: %s" % ', '.join(["'%s'" % el for el in self._datakeys])
        fkeys =  "File keys: %s" % ', '.join(["'%s'" % el for el in self._filekeys])
        print '\n'.join([pkeys, dkeys, fkeys])
        if summary: return

        for spec in  list(self):
            pinfo = ', '.join(['%s=%s' % (pkey, spec[pkey]) for pkey in self._partitionedkeys]) + ' | '
            dinfo = ', '.join(['%s=%s' % (dkey, spec[dkey]) for dkey in self._datakeys]) + ' | '
            finfo = ', '.join(['%s=%s' % (fkey, self.filelist(spec[fkey], basename)) for fkey in self._filekeys])
            print ''.join([pinfo, dinfo, finfo])

    def __repr__(self):
        (_, root_dir) = os.path.split(self.root_directory)
        logging.info('Collate contains %d entries ' % len(self.spec_list))
        return "Collate('%s', %s)" % (root_dir, '<spec_list>')

class Select:
    """ Only accepts string data type - but can view fields numerically
        Accepts specifier or list of dictionaries
        """

    def __init__(self, spec=[], float_keys=[], int_keys=[], hidden_keys=None, visible_keys=None):

        specs = list(self._valid_spec(spec) if not isinstance(spec, TaskSpecifier)
                             else itertools.chain.from_iterable(spec))

        self._hidden_keys = None
        self._visible_keys = None
        self.speclist = None
        self.float_keys = []
        self.int_keys = []
        self.selector_array = None
        self.view_array = None
        self._fromlist(specs, float_keys, int_keys)

        if None not in [hidden_keys, visible_keys]:
            raise Exception('Both hidden_keys and visible_keys cannot be set')
        if   hidden_keys is not None:   self.set_hidden(hidden_keys)
        elif visible_keys is not None:  self.set_visible(visible_keys)
        else: self.set_hidden([])

    def _valid_spec(self, speclist):
        str_types = [str, np.string_]
        all_strings = all([type(k) in str_types and type(v) in str_types
                           for spec in speclist for (k,v) in spec.items()])
        if not all_strings: raise Exception('All keys and values must be strings (and not unicode)')
        return speclist

    def _fromlist(self, speclist, float_keys=[], int_keys=[]):
        fields = sorted(set([str(k) for spec in speclist for k in spec.keys()]))
        values = [tuple([spec.get(f,'') for f in fields]) for spec in speclist]
        array =  np.array(values)
        array.dtype = np.dtype([(f, array.dtype) for f in fields ])
        self.fromarray(array, float_keys, int_keys)

    def __array__(self): return self.selector_array

    def __getattr__(self, name):
        if name in self._hidden_keys: raise Exception('Desired key available but hidden')
        if self.selector_array != []:
            view = self.view_array[self._visible_keys].view(np.recarray)
            return getattr(view, name).flatten()
        else: raise Exception('No data loaded')

    def __getitem__(self, name):
        return self.view_array[self._visible_keys].view(np.recarray)[name].flatten()

    def set_hidden(self, hidden_list):
        assert set(hidden_list) <= set(self.keys()), "Hidden keys do not exist"
        self._visible_keys = [k for k in self.keys() if k not in hidden_list]
        self._hidden_keys = hidden_list

    def set_visible(self, visible_list):
        assert set(visible_list) <= set(self.keys()), "Visible keys do not exist"
        self._hidden_keys = [k for k in self.keys() if k not in visible_list]
        self._visible_keys = visible_list

    def keys(self): return list(self.selector_array.dtype.names)

    def fromarray(self, array, float_keys=[], int_keys=[]):
        allowed_types = ['S', 'U']
        kinds = [array.dtype[name].kind for name in array.dtype.names]
        assert all(k in allowed_types for k in kinds), 'All dtypes must be of string type'
        self.selector_array = array
        self.set_hidden([])
        self.view(float_keys, int_keys)
        self.speclist = self.tolist()
        return self

    def tolist(self, selection=None, include_hidden=False):
        length = self.selector_array.shape[0]
        only_visible = (self._visible_keys is not None) and not include_hidden
        sel = selection if (selection is not None) else [True] * length
        visible_keys =  self._visible_keys if only_visible else self.keys()
        selected = self.selector_array[visible_keys][selection].flatten()
        return [ dict(zip(visible_keys, line)) for line in selected]

    def subselector(self, condition):
        return Select(self.tolist(condition), visible_keys=self._visible_keys)

    def select(self, selection, *data):
        ' Accepts lists/arrays of data or collation keys'
        string_keys = [ d for d in data if type(d) == str]
        assert set(string_keys) <= set(self.keys()), \
            "Specified string key(s) not available"
        data = [d if (d not in string_keys) else self.view_array[d] for d in data]
        data_lengths = [len(d) for d in data]
        assert [dlen == len(selection) for dlen in data_lengths], \
            "Length/shape of data and length of selection must match"
        selected = []
        for d in data:
            if isinstance(d,np.ndarray): selected.append(d[selection])
            else:                        selected.append([el for (i,el)
                                                          in enumerate(list(d))
                                                          if selection[i]])
        if len(selected) == 1: return selected[0]
        else:                  return tuple(selected)

    def view(self, float_keys=[], int_keys=[],  tid_key='tid'):
        ''' Called without arguments resets the view to the underlying strings '''
        all_int_keys = (int_keys+[tid_key] if (tid_key in self.keys()) else int_keys)
        self.float_keys = float_keys; self.int_keys = int_keys
        if not set(float_keys+all_int_keys) <= set(self.keys()):
            raise Exception('Element of float_view and int_view not in available fields:' % self.keys())

        all_float_keys = float_keys + int_keys # Numpy wants conversion to float before conversion to int
        dtype  = [(d[0], float) if (d[0] in all_float_keys) else d for d in self.selector_array.dtype.descr]
        self.view_array = self.selector_array.astype(dtype)
        dtype  = [(d[0], int) if (d[0] in all_int_keys) else d for d in self.view_array.dtype.descr]
        self.view_array = self.view_array.astype(dtype)

    def __repr__(self):
        info = (repr(self.float_keys), repr(self.int_keys),
                self.selector_array.shape, ', '.join(self.keys()))
        return "Select(float_keys=%s, int_keys=%s)\n#Shape %s, Fields: %s" % info
